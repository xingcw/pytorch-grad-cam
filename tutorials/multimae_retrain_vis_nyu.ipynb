{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.transforms.functional as TF\n",
    "from gradcam.utils.image import show_cam_on_image\n",
    "from gradcam.multimae_cam import MultiMAECAM\n",
    "\n",
    "from multimae.models.multimae import pretrain_multimae_base\n",
    "from multimae.utils.plot_utils import plot_predictions\n",
    "from multimae.models.criterion import MaskedCrossEntropyLoss, MaskedMSELoss, MaskedL1Loss\n",
    "from pipelines.utils.data_utils import preprocess_multimae_inputs_in_batch\n",
    "from functools import partial\n",
    "from multimae.models.input_adapters import PatchedInputAdapter, SemSegInputAdapter\n",
    "from multimae.models.output_adapters import SpatialOutputAdapter\n",
    "from multimae.utils.data_constants import CUSTOM_SEMSEG_NUM_CLASSES, COCO_SEMSEG_NUM_CLASSES\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flightmare_path = Path(os.environ[\"FLIGHTMARE_PATH\"])\n",
    "device = torch.device('cuda')\n",
    "prefix = \"0000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multimae_path = flightmare_path.parent / \"vision_backbones/MultiMAE\"\n",
    "sample_rgb = multimae_path / f\"datasets/nyu/test/rgb/data/{prefix}.png\"\n",
    "sample_depth = multimae_path / f\"datasets/nyu/test/depth/data/{prefix}.png\"\n",
    "sample_semseg = multimae_path / f\"datasets/nyu/test/semseg/data/{prefix}.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(str(sample_rgb))\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "image_float = torch.from_numpy(image).float().permute(2, 0, 1) / 255.0\n",
    "c, h, w = image_float.shape\n",
    "\n",
    "image_float = TF.center_crop(image_float, min([h, w]))\n",
    "image_float = TF.resize(image_float, 224)\n",
    "image_float = image_float.permute(1, 2, 0).numpy().astype(np.float32)\n",
    "print(image_float.shape)\n",
    "\n",
    "image = Image.fromarray(image)\n",
    "\n",
    "semseg = cv2.imread(str(sample_semseg))\n",
    "depth = cv2.imread(str(sample_depth))\n",
    "\n",
    "fig, axs = plt.subplots(1, 3)\n",
    "axs[0].imshow(image)\n",
    "axs[0].axis('off')\n",
    "\n",
    "axs[1].imshow(semseg)\n",
    "axs[1].axis('off')\n",
    "\n",
    "axs[2].imshow(depth)\n",
    "axs[2].axis('off')\n",
    "\n",
    "print(depth.shape)\n",
    "print(depth.max())\n",
    "print(depth.min())\n",
    "\n",
    "depth = depth[:, :, 0].astype(np.float32) / depth.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOMAINS = ['rgb', 'depth', 'semseg']\n",
    "DOMAIN_CONF = {\n",
    "    'rgb': {\n",
    "        'channels': 3,\n",
    "        'stride_level': 1,\n",
    "        'input_adapter': partial(PatchedInputAdapter, num_channels=3),\n",
    "        'output_adapter': partial(SpatialOutputAdapter, num_channels=3),\n",
    "        'loss': MaskedMSELoss,\n",
    "    },\n",
    "    'depth': {\n",
    "        'channels': 1,\n",
    "        'stride_level': 1,\n",
    "        'input_adapter': partial(PatchedInputAdapter, num_channels=1),\n",
    "        'output_adapter': partial(SpatialOutputAdapter, num_channels=1),\n",
    "        'loss': MaskedL1Loss,\n",
    "    },\n",
    "    'semseg': {\n",
    "        'num_classes': COCO_SEMSEG_NUM_CLASSES,\n",
    "        'stride_level': 4,\n",
    "        'input_adapter': partial(SemSegInputAdapter, num_classes=COCO_SEMSEG_NUM_CLASSES,\n",
    "                                 dim_class_emb=64, interpolate_class_emb=False),\n",
    "        'output_adapter': partial(SpatialOutputAdapter, num_channels=COCO_SEMSEG_NUM_CLASSES),\n",
    "        'loss': partial(MaskedCrossEntropyLoss, label_smoothing=0.0),\n",
    "    },\n",
    "}\n",
    "\n",
    "input_adapters = {\n",
    "    domain: dinfo['input_adapter'](\n",
    "        patch_size_full=16, \n",
    "        stride_level=DOMAIN_CONF[domain]['stride_level'])\n",
    "    for domain, dinfo in DOMAIN_CONF.items()\n",
    "}\n",
    "\n",
    "output_adapters = {\n",
    "    domain: dinfo['output_adapter'](\n",
    "        patch_size_full=16,\n",
    "        stride_level=DOMAIN_CONF[domain]['stride_level'],\n",
    "        dim_tokens=256,\n",
    "        use_task_queries=True,\n",
    "        depth=2,\n",
    "        num_heads=8,\n",
    "        use_xattn=True,\n",
    "        context_tasks=DOMAINS,\n",
    "        task=domain\n",
    "    )\n",
    "    for domain, dinfo in DOMAIN_CONF.items()\n",
    "}\n",
    "\n",
    "output_adapters['norm_rgb'] = DOMAIN_CONF['rgb']['output_adapter'](\n",
    "            stride_level=DOMAIN_CONF['rgb']['stride_level'],\n",
    "            patch_size_full=16,\n",
    "            dim_tokens=256,\n",
    "            depth=2,\n",
    "            num_heads=8,\n",
    "            use_task_queries=True,\n",
    "            task='rgb',\n",
    "            context_tasks=DOMAINS,\n",
    "            use_xattn=True\n",
    "        )\n",
    "\n",
    "model = pretrain_multimae_base(input_adapters=input_adapters, output_adapters=output_adapters)\n",
    "pretrained_model_path = multimae_path / \"results/pretrain/multimae-b_98_rgb+-semseg_400e/03-07-00-37-55/checkpoint-19.pth\"\n",
    "ckpt = torch.load(pretrained_model_path, map_location='cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(ckpt['model'], strict=True)\n",
    "model.to(\"cuda\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process RGB, depth and semseg to the MultiMAE input format\n",
    "input_dict = {\n",
    "    \"rgb\": np.expand_dims(image, [0, -1]),\n",
    "    \"depth\": np.expand_dims(depth, [0, -2, -1]),\n",
    "    \"semseg\": np.expand_dims(semseg[:, :, 0], [0, 3, 4])\n",
    "}\n",
    "\n",
    "print(input_dict[\"rgb\"].shape)\n",
    "print(input_dict[\"depth\"].shape)\n",
    "print(input_dict[\"semseg\"].shape)\n",
    "\n",
    "processed_inputs = preprocess_multimae_inputs_in_batch(input_dict, batch_axis=True)\n",
    "    \n",
    "# To GPU\n",
    "processed_inputs = {k: v.squeeze(-1).to(\"cuda\") for k,v in processed_inputs.items()}\n",
    "\n",
    "print(processed_inputs[\"rgb\"].shape)\n",
    "print(processed_inputs[\"depth\"].shape)\n",
    "print(processed_inputs[\"semseg\"].shape)\n",
    "\n",
    "inputs = {k: processed_inputs[k] for k in DOMAINS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "torch.manual_seed(seed) # change seed to resample new mask\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "cudnn.benchmark = True\n",
    "\n",
    "target_layers = [model.encoder[-1].norm1]\n",
    "cam = MultiMAECAM(model=model, target_layers=target_layers, use_cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vis(res, image_float, grayscale_cam):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    axs = ImageGrid(fig, 111, nrows_ncols=(2, 3), axes_pad=0)\n",
    "\n",
    "    axs[0].imshow(res[\"rgb_input\"])\n",
    "    axs[0].axis('off')\n",
    "    axs[0].set_title(\"RGB\")\n",
    "\n",
    "    axs[1].imshow(res[\"depth_input\"])\n",
    "    axs[1].axis('off')\n",
    "    axs[1].set_title(\"Depth\")\n",
    "\n",
    "    axs[2].imshow(res[\"semseg_input\"])\n",
    "    axs[2].axis('off')\n",
    "    axs[2].set_title(\"Semseg\")\n",
    "\n",
    "    cam_rgb = show_cam_on_image(image_float, grayscale_cam[0, :, :], use_rgb=True)\n",
    "    axs[3].imshow(cam_rgb)\n",
    "    axs[3].axis('off')\n",
    "\n",
    "    axs[4].imshow(cam_rgb)\n",
    "    axs[4].axis('off')\n",
    "\n",
    "    axs[5].imshow(cam_rgb)\n",
    "    axs[5].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = {\n",
    "    \"rgb\": MaskedMSELoss(),\n",
    "    \"depth\": MaskedL1Loss(),\n",
    "    \"semseg\": MaskedCrossEntropyLoss(stride=4)\n",
    "}\n",
    "preds, task_masks, grayscale_cam = cam(input_tensor=inputs, targets=targets, num_encoded_tokens=196, mask_type=\"non-overlap\")\n",
    "preds = {domain: pred.detach().cpu() for domain, pred in preds.items()}\n",
    "masks = {domain: mask.detach().cpu() for domain, mask in task_masks.items()}\n",
    "\n",
    "res = plot_predictions(inputs, preds, masks, show_img=True)\n",
    "plot_vis(res, image_float, grayscale_cam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = {\n",
    "    \"rgb\": MaskedMSELoss()\n",
    "}\n",
    "preds, task_masks, grayscale_cam = cam(\n",
    "    input_tensor=inputs, \n",
    "    targets=targets, \n",
    "    # inputs for multimae preditions\n",
    "    num_encoded_tokens=196, \n",
    "    mask_inputs=True,\n",
    "    task_masks=task_masks)\n",
    "\n",
    "preds = {domain: pred.detach().cpu() for domain, pred in preds.items()}\n",
    "masks = {domain: mask.detach().cpu() for domain, mask in task_masks.items()}\n",
    "\n",
    "res = plot_predictions(inputs, preds, masks, show_img=False)\n",
    "plot_vis(res, image_float, grayscale_cam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = {\n",
    "    \"depth\": MaskedL1Loss()\n",
    "}\n",
    "preds, task_masks, grayscale_cam = cam(\n",
    "    input_tensor=inputs, \n",
    "    targets=targets, \n",
    "    # inputs for multimae preditions\n",
    "    num_encoded_tokens=196, \n",
    "    mask_inputs=True,\n",
    "    task_masks=task_masks)\n",
    "\n",
    "preds = {domain: pred.detach().cpu() for domain, pred in preds.items()}\n",
    "masks = {domain: mask.detach().cpu() for domain, mask in task_masks.items()}\n",
    "\n",
    "res = plot_predictions(inputs, preds, masks, show_img=False)\n",
    "plot_vis(res, image_float, grayscale_cam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = {\n",
    "    \"semseg\": MaskedCrossEntropyLoss(stride=4)\n",
    "}\n",
    "preds, task_masks, grayscale_cam = cam(\n",
    "    input_tensor=inputs, \n",
    "    targets=targets, \n",
    "    # inputs for multimae preditions\n",
    "    num_encoded_tokens=196, \n",
    "    mask_inputs=True,\n",
    "    task_masks=task_masks)\n",
    "\n",
    "preds = {domain: pred.detach().cpu() for domain, pred in preds.items()}\n",
    "masks = {domain: mask.detach().cpu() for domain, mask in task_masks.items()}\n",
    "\n",
    "res = plot_predictions(inputs, preds, masks, show_img=False)\n",
    "plot_vis(res, image_float, grayscale_cam)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flight",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7605093629cb18fcce5e9851ee580088d6671b36cffe2f96996ec104406ff14d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
